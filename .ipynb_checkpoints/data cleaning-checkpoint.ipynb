{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perception of Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the required packages \n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Migaliza Lung'ahu\\Documents\\Personal Portfolio\\twitter_dataset\\*.csv\n",
      "C:\\Users\\Migaliza Lung'ahu\\Documents\\Personal Portfolio\\twitter_dataset\\cancer_data.csv\n",
      "C:\\Users\\Migaliza Lung'ahu\\Documents\\Personal Portfolio\\twitter_dataset\\cancer_data10.csv\n",
      "C:\\Users\\Migaliza Lung'ahu\\Documents\\Personal Portfolio\\twitter_dataset\\cancer_data11.csv\n",
      "C:\\Users\\Migaliza Lung'ahu\\Documents\\Personal Portfolio\\twitter_dataset\\cancer_data12.csv\n",
      "C:\\Users\\Migaliza Lung'ahu\\Documents\\Personal Portfolio\\twitter_dataset\\cancer_data14.csv\n",
      "C:\\Users\\Migaliza Lung'ahu\\Documents\\Personal Portfolio\\twitter_dataset\\cancer_data15.csv\n",
      "C:\\Users\\Migaliza Lung'ahu\\Documents\\Personal Portfolio\\twitter_dataset\\cancer_data2.csv\n",
      "C:\\Users\\Migaliza Lung'ahu\\Documents\\Personal Portfolio\\twitter_dataset\\cancer_data3.csv\n",
      "C:\\Users\\Migaliza Lung'ahu\\Documents\\Personal Portfolio\\twitter_dataset\\cancer_data4.csv\n",
      "C:\\Users\\Migaliza Lung'ahu\\Documents\\Personal Portfolio\\twitter_dataset\\cancer_data5.csv\n",
      "C:\\Users\\Migaliza Lung'ahu\\Documents\\Personal Portfolio\\twitter_dataset\\cancer_data9.csv\n",
      "re.compile(\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\")\n",
      "object\n",
      "               User                      Location      created On  \\\n",
      "0         wood_ingo                 Luanda, Kenya  7/31/2019 8:07   \n",
      "1    smiIingforthis                     the knees  7/31/2019 8:07   \n",
      "2     Damo_McGregor                United Kingdom  7/31/2019 8:07   \n",
      "3           SKhobes               Marsabit, Kenya  7/31/2019 8:07   \n",
      "4       mayers_life          Colorado Springs, CO  7/31/2019 8:07   \n",
      "5     DerekCStewart                Nottingham, UK  7/31/2019 8:07   \n",
      "6         iiiushiii                Lucknow, India  7/31/2019 8:07   \n",
      "7       KathurimaDC                            üåê   7/31/2019 8:07   \n",
      "8     OnyangoCarlos                Nairobi, Kenya  7/31/2019 8:07   \n",
      "9       Zenaidalulu                         Kenya  7/31/2019 8:07   \n",
      "10     zembla_98403          A far, northern land  7/31/2019 8:07   \n",
      "11        _drewseph                   Los Angeles  7/31/2019 8:07   \n",
      "12            zevav           Geneva, Switzerland  7/31/2019 8:07   \n",
      "13     aca_nikolic7         –°—Ä–±–∏—ò–∞~√ñsterreich~USA  7/31/2019 8:07   \n",
      "14     pinkybhavnal   Dubai. UAE. (Hsp-Pb, India)  7/31/2019 8:07   \n",
      "15    FXspacetrader                        LONDON  7/31/2019 8:07   \n",
      "16       SimonBalto  American Midwest, proudly so  7/31/2019 8:07   \n",
      "17  tshirtshoppings                            ca  7/31/2019 8:07   \n",
      "18  543DentalCentre                          Hull  7/31/2019 8:07   \n",
      "19     meghanpope_x              Poulton, England  7/31/2019 8:07   \n",
      "\n",
      "                                                Tweet  \\\n",
      "0   @citizentvkenya Apology or no apology, we have...   \n",
      "1       @ROBINSBVCKLEY hufflepuff, cancer, robin :)))   \n",
      "2   RT @Fact: Onions have been proven to lower cho...   \n",
      "3   RT @Donsarigo: In 2014 I traveled to Marsabit ...   \n",
      "4   RT @Fact: Onions have been proven to lower cho...   \n",
      "5   RT @PeteWheatstone: @bowelcancerman Patrick, i...   \n",
      "6   RT @ANI: Delhi: A 28-year-old non-smoking woma...   \n",
      "7   RT @daktari1: Cancer is like terrorism. It‚Äôs n...   \n",
      "8   At Least 80 Kenyans Die Daily Due To Cancer ht...   \n",
      "9   RT @ythera: @DopeWas @KNH_hospital @ItsMainaKa...   \n",
      "10  RT @SaraJBenincasa: Marianne Williamson used t...   \n",
      "11  RT @brosandprose: Marianne Williamson has impl...   \n",
      "12  RT @brosandprose: Marianne Williamson has impl...   \n",
      "13  RT @RaniaKhalek: US sanctions on Iran are deny...   \n",
      "14  RT @ANI: Delhi: A 28-year-old non-smoking woma...   \n",
      "15  @BBCJonSopel @BBCr4today @BorisJohnson @realDo...   \n",
      "16  RT @brosandprose: Marianne Williamson has impl...   \n",
      "17  Snoopy Believe Lung Cancer White Awareness TSh...   \n",
      "18  RT @Oralieve_UK: Movie Star Val Kilmer attends...   \n",
      "19  RT @Brink_Thinker: This princess dressed as a ...   \n",
      "\n",
      "                                                links  \n",
      "0                                                  []  \n",
      "1                                                  []  \n",
      "2                                                  []  \n",
      "3                                                  []  \n",
      "4                                                  []  \n",
      "5                                                  []  \n",
      "6                                                  []  \n",
      "7                                                  []  \n",
      "8   [https://t.co/GvsgCwgChu, https://t.co/ahJqYoU...  \n",
      "9                                                  []  \n",
      "10                                                 []  \n",
      "11                                                 []  \n",
      "12                                                 []  \n",
      "13                                                 []  \n",
      "14                                                 []  \n",
      "15                          [https://t.co/5zMgSbn1Sj]  \n",
      "16                                                 []  \n",
      "17  [https://t.co/Qp2PEGV5CY, https://t.co/n8hlAAm...  \n",
      "18                                                 []  \n",
      "19                                                 []  \n"
     ]
    }
   ],
   "source": [
    "#specify the pattern of the file\n",
    "pattern = \"C:\\\\Users\\\\Migaliza Lung'ahu\\\\Documents\\\\Personal Portfolio\\\\twitter_dataset\\\\*.csv\"\n",
    "\n",
    "print(pattern)\n",
    "#search for all the files \n",
    "csv_files = glob.glob(pattern, recursive=True)\n",
    "#print(csv_files)\n",
    "\n",
    "#loop through the files to read all the files and append them on a list\n",
    "df = []\n",
    "\n",
    "for file in csv_files:\n",
    "    print(file)\n",
    "    csv_file = pd.read_csv(file)\n",
    "    df.append(csv_file)\n",
    "\n",
    "#concatenate the all the files read ignore the index and drop the second column\n",
    "df_record = pd.concat(df, ignore_index=False).reset_index(drop=True).drop(\"Unnamed: 0\", axis=1)\n",
    "\n",
    "# Remove all tweets without location indicated\n",
    "df_record = df_record.dropna().reset_index(drop = True)\n",
    "\n",
    "#all the country names with no alphabetical characters should be renamed to unknown\n",
    "#df_record[\"Location\"] = df_record.Location.apply(labmda x: re.replace('[A-Z]\\w*'))\n",
    "\n",
    "# write a regular expresion to capture all the urls and save them to a different column\n",
    "re_pattern = re.compile(\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\")\n",
    "\n",
    "print(re_pattern)\n",
    "#print(\"Original string: \",text)\n",
    "df_record['links'] = df_record.Tweet.apply(lambda x: re.findall(\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\", x))\n",
    "#df_record['links'] = str(type(1))\n",
    "\n",
    "print(df_record[\"links\"].dtypes)\n",
    "#remove the [] from the Links colmns\n",
    "#tips.total_dollar.apply(lambda x: x.replace('$', ''))\n",
    "#df_record[\"links\"] = df_record.links.apply(lambda x: x.replace(\"[,]\",''))\n",
    "print(df_record.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning process\n",
    "- next steps is to remove peoples names fromt the tweet and only leave the text\n",
    "- find if the text says anything concerning cancer the disease and cancer the star,if contains anything other than cancer the star,\n",
    "- remove that record\n",
    "- remove special characters from the Location\n",
    "- remove special characters from the Tweet\n",
    "- download a list of country code and the countries they represent, then use that to assign the names to the \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 77181 entries, 0 to 77180\n",
      "Data columns (total 5 columns):\n",
      "User          77181 non-null object\n",
      "Location      77181 non-null object\n",
      "created On    77181 non-null object\n",
      "Tweet         77181 non-null object\n",
      "links         77181 non-null object\n",
      "dtypes: object(5)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "#explore the dataframe\n",
    "#print(df_record.shape)\n",
    "#print(df_record.describe)\n",
    "#print(df_record.head())\n",
    "df_record.head()\n",
    "df_record.tail()\n",
    "df_record.info()\n",
    "df_record.tail()\n",
    "\n",
    "df_record.to_csv(\"/cleaned_data/cancer_perceptions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
